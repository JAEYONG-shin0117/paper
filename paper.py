import streamlit as st
from groq import Groq
from PIL import Image
import base64
from io import BytesIO

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
# ==========================================
st.set_page_config(
    page_title="Paper Writer (Llama 4 Vision)", 
    page_icon="ğŸ“„", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.markdown(
    """
    <style>
    [data-testid="stSidebar"] {display: none;}
    </style>
    """,
    unsafe_allow_html=True
)

# ==========================================
# [ì¤‘ìš”] Groq API í‚¤ ë¡œë“œ (Secrets ì—°ë™)
# ==========================================
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except (FileNotFoundError, KeyError):
    st.error("ğŸš¨ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.info("ğŸ’¡ [ë°°í¬ í›„] Streamlit Cloud ì•± ì„¤ì • > Secrets ë©”ë‰´ì— 'GROQ_API_KEY'ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.info("ğŸ’¡ [ë¡œì»¬ ì‹¤í–‰] .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ==========================================
# [í•¨ìˆ˜] ì´ë¯¸ì§€ ë³€í™˜ (ë¦¬ì‚¬ì´ì§• ì¶”ê°€)
# ==========================================
def encode_image_to_base64(image):
    # Llama 4ëŠ” 4MB ì œí•œì´ ì—„ê²©í•˜ë¯€ë¡œ, ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì§•
    max_size = (1024, 1024)
    image.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    buffered = BytesIO()
    image = image.convert("RGB")
    image.save(buffered, format="JPEG", quality=85) # ìš©ëŸ‰ ìµœì í™”
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# ==========================================
# [í•¨ìˆ˜] ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¬¸ ìƒì„± ë¡œì§
# ==========================================
def generate_natural_method(api_key, domain_text, image_list):
    client = Groq(api_key=api_key)
    
    # 1. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_prompt = f"""
    You are an elite AI researcher writing the **"Proposed Method"** section for a top-tier conference paper (e.g., CVPR, NeurIPS).
    
    **GOAL:** Analyze the attached architecture diagrams and write a **cohesive, logically flowing** description of the proposed framework.
    
    **INSTRUCTIONS:**
    1. **Narrative Flow:** Do NOT force the text into too many sub-sections. Prioritize a smooth narrative.
    2. **Synthesis:** Synthesize multiple images into a single coherent explanation.
    3. **Academic Tone:** Use high-level academic English and **LaTeX** for variables ($x$, $L_{{total}}$).
    4. **Detail:** Describe exactly what happens in the pipeline, transitioning naturally between components.

    [Context Info]
    - **Domain:** {domain_text}
    - **Visual Input:** {len(image_list)} diagram(s).
    
    Start writing the "Proposed Method" section now.
    """

    # 2. ë©”ì‹œì§€ í˜ì´ë¡œë“œ êµ¬ì„±
    content_payload = [{"type": "text", "text": user_prompt}]

    for img in image_list:
        base64_img = encode_image_to_base64(img)
        content_payload.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_img}",
            },
        })

    # 3. ëª¨ë¸ ID ì„¤ì • (ìµœì‹  Llama 4 Scout ì ìš©)
    # ì´ì „ ëª¨ë¸(11b/90b-preview)ì€ ì¢…ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ì•„ë˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    model_id = "meta-llama/llama-4-scout-17b-16e-instruct"

    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": content_payload,
                }
            ],
            model=model_id, 
            temperature=0.5, 
            max_tokens=6000, 
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ==========================================
# [UI] í™”ë©´ êµ¬ì„±
# ==========================================
st.title("ğŸ“„ AI Paper Writer(LMMLab)")

col1, col2 = st.columns([1, 1])

with col1:
    domain_input = st.text_area(
        "1. ë„ë©”ì¸ ì„¤ëª… ë° í•µì‹¬ í‚¤ì›Œë“œ",
        height=300,
        placeholder="ì˜ˆ: Multi-agent debating framework using ViT and LLM..."
    )

with col2:
    uploaded_files = st.file_uploader(
        "2. ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)", 
        type=["jpg", "png", "jpeg"],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.write(f"âœ… ì´ {len(uploaded_files)}ì¥ì˜ ì´ë¯¸ì§€ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        tabs = st.tabs([f"ì´ë¯¸ì§€ {i+1}" for i in range(len(uploaded_files))])
        
        pil_images = []
        for i, uploaded_file in enumerate(uploaded_files):
            image = Image.open(uploaded_file)
            pil_images.append(image)
            with tabs[i]:
                st.image(image, caption=uploaded_file.name, use_container_width=True)
    else:
        pil_images = []

st.divider()

if st.button("ğŸš€ ë…¼ë¬¸ ì‘ì„± ì‹œì‘", type="primary", use_container_width=True):
    if not pil_images:
        st.error("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        with st.spinner(f'ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”....'):
            result = generate_natural_method(GROQ_API_KEY, domain_input, pil_images)
            
            st.divider()
            if "âŒ" in result:
                st.error(result)
            else:
                st.subheader("ğŸ“„ ìƒì„± ê²°ê³¼")
                st.markdown(result)
                st.divider()
                st.text_area("ì „ì²´ ë³µì‚¬ (Ctrl+A)", value=result, height=800)
