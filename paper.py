import streamlit as st
from groq import Groq
from PIL import Image
import base64
from io import BytesIO

# ==========================================
# [ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
# ==========================================
st.set_page_config(
    page_title="Paper Writer (Multi-Image)", 
    page_icon="ğŸ“„", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.markdown(
    """
    <style>
    [data-testid="stSidebar"] {display: none;}
    </style>
    """,
    unsafe_allow_html=True
)

# ==========================================
# [ì¤‘ìš”] Groq API í‚¤ ë¡œë“œ (Secrets ì—°ë™)
# ==========================================
# ì´ë¯¸ Secrets ì„¤ì •ì„ ì™„ë£Œí•˜ì…¨ìœ¼ë¯€ë¡œ, ì´ ì½”ë“œê°€ ì •ìƒ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except (FileNotFoundError, KeyError):
    st.error("ğŸš¨ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.info("ğŸ’¡ [ë°°í¬ í›„] Streamlit Cloud ì•± ì„¤ì • > Secrets ë©”ë‰´ì— 'GROQ_API_KEY'ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.info("ğŸ’¡ [ë¡œì»¬ ì‹¤í–‰] .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# ==========================================
# [í•¨ìˆ˜] ì´ë¯¸ì§€ ë³€í™˜
# ==========================================
def encode_image_to_base64(image):
    buffered = BytesIO()
    image = image.convert("RGB")
    image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# ==========================================
# [í•¨ìˆ˜] ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¬¸ ìƒì„± ë¡œì§ (ë‹¤ì¤‘ ì´ë¯¸ì§€ ì§€ì›)
# ==========================================
def generate_natural_method(api_key, domain_text, image_list):
    client = Groq(api_key=api_key)
    
    # 1. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_prompt = f"""
    You are an elite AI researcher writing the **"Proposed Method"** section for a top-tier conference paper (e.g., CVPR, NeurIPS).
    
    **GOAL:** Analyze the attached architecture diagrams (there may be multiple images detailing different parts) and write a **cohesive, logically flowing** description of the proposed framework.
    
    **INSTRUCTIONS:**
    1. **No Artificial Segmentation:** Do NOT force the text into too many sub-sections. Prioritize a **smooth narrative flow**.
    2. **Synthesize Information:** If multiple images are provided (e.g., overall architecture + detailed module), synthesize them into a single coherent explanation.
    3. **Academic Rigor:** Use high-level academic English. Use **LaTeX** for all variables and formulas ($x$, $L_{{total}}$).
    4. **Detail Oriented:** Describe exactly what is happening in the images. Start with the overall pipeline and naturally transition into the details of specific components.

    [Context Info]
    - **Domain:** {domain_text}
    - **Visual Input:** {len(image_list)} architecture diagram(s) attached.

    **Structure Guide:**
    - Start with a strong paragraph summarizing the overall framework.
    - Dedicate substantial paragraphs to detailing the key modules shown in the diagrams.
    - Conclude with the training objectives or inference strategy.
    
    Start writing the "Proposed Method" section now.
    """

    # 2. ë©”ì‹œì§€ í˜ì´ë¡œë“œ êµ¬ì„±
    content_payload = [{"type": "text", "text": user_prompt}]

    for img in image_list:
        base64_img = encode_image_to_base64(img)
        content_payload.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{base64_img}",
            },
        })

    # 3. ëª¨ë¸ ID ì„¤ì • (ìˆ˜ì •ë¨: 90b -> 11b)
    # âš ï¸ Groqì—ì„œ 90b vision ëª¨ë¸ì„ ë‚´ë ¸ìœ¼ë¯€ë¡œ 11bë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
    model_id = "llama-3.2-11b-vision-preview" 

    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": content_payload,
                }
            ],
            model=model_id, 
            temperature=0.5, 
            max_tokens=6000, 
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"âŒ Groq ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ==========================================
# [UI] í™”ë©´ êµ¬ì„±
# ==========================================
st.title("ğŸ“„ AI Paper Writer (Multi-Image Support)")

col1, col2 = st.columns([1, 1])

with col1:
    domain_input = st.text_area(
        "1. ë„ë©”ì¸ ì„¤ëª… ë° í•µì‹¬ í‚¤ì›Œë“œ",
        height=300,
        placeholder="ì˜ˆ: Multi-agent debating framework using ViT and LLM..."
    )

with col2:
    uploaded_files = st.file_uploader(
        "2. ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ì„ íƒ ê°€ëŠ¥)", 
        type=["jpg", "png", "jpeg"],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.write(f"âœ… ì´ {len(uploaded_files)}ì¥ì˜ ì´ë¯¸ì§€ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        tabs = st.tabs([f"ì´ë¯¸ì§€ {i+1}" for i in range(len(uploaded_files))])
        
        pil_images = []
        for i, uploaded_file in enumerate(uploaded_files):
            image = Image.open(uploaded_file)
            pil_images.append(image)
            with tabs[i]:
                st.image(image, caption=uploaded_file.name, use_container_width=True)
    else:
        pil_images = []

st.divider()

if st.button("ğŸš€ ìì—°ìŠ¤ëŸ¬ìš´ ë…¼ë¬¸ ì‘ì„± ì‹œì‘", type="primary", use_container_width=True):
    if not pil_images:
        st.error("ì´ë¯¸ì§€ë¥¼ í•œ ì¥ ì´ìƒ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    else:
        with st.spinner(f'AIê°€ {len(pil_images)}ì¥ì˜ ê·¸ë¦¼ê³¼ ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬ ê¸€ì„ ì“°ê³  ìˆìŠµë‹ˆë‹¤...'):
            result = generate_natural_method(GROQ_API_KEY, domain_input, pil_images)
            
            st.divider()
            if "âŒ" in result:
                st.error(result)
            else:
                st.subheader("ğŸ“„ ìƒì„± ê²°ê³¼")
                st.markdown(result)
                st.divider()
                st.text_area("ì „ì²´ ë³µì‚¬ (Ctrl+A)", value=result, height=800)
